# Проект "Предсказание категории товара по контенту"

## 1. Описание проекта

Проект решает задачу классификации товаров по категориям на основе текстовых описаний и метаданных.  
Модель обучается на предоставленном датасете (Kaggle), сервис предоставляет API для получения предсказаний через `/predict`.  

Идея решения:
- Объединяем текстовые поля (`name`, `description`, `vendor`, `model`, `type_prefix`) в один текст.
- Преобразуем текст в признаки с помощью TF-IDF для слов и символов.
- Обучаем линейный классификатор SGDClassifier с `partial_fit` на чанках данных для экономии памяти.
- Сервис Flask возвращает категорию товара по JSON-запросу.

---

## 2. Запуск сервиса

Проект запускается из корня проекта командой:
```
./run_service.sh
```
Модель, словари и данные храняться на S3/MinIO, они подгружаются автоматически при запуске скрипта.

Сервис предоставляет два эндпоинта:

- /health — проверка работоспособности
- /predict — предсказание категории товара

Пример запроса /predict:
```
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "url":"https://example.com/product/1",
    "texts":{
      "name":"Мягкая кровать",
      "description":"красивая кровать",
      "vendor":"Орматек",
      "model":"Como 1",
      "type_prefix":"Кровать"
    },
    "image_url":"https://example.com/image.jpg"
  }'
```
Пример ответа:
```
{"category_ind": 42}
```

## 3. Модель и признаки

### Особенности модели и ее обучения
В проекте используется линейный классификатор **SGDClassifier**, обученный с помощью метода partial_fit. Это позволило обработать большие наборы данных по чанкам, не загружая весь датасет сразу в память.
- Обучение по чанкам: данные делятся на блоки по 5000 примеров, модель обновляется постепенно.
- Валидация: после обработки каждого чанка проводится проверка на отдельной валидационной выборке (VAL_SIZE = 20 000). Сохраняется лучшая модель по accuracy.

### Признаки
- **TF-IDF для слов**: учитываются униграммы и биграммы (ngram_range=(1,2))
- **TF-IDF для символов**: учитываются n-граммы символов длиной 3–5 (ngram_range=(3,5)).
- **Объединение признаков**: полученные признаки для слов и символов объединяются в одну матрицу X для подачи в модель.

## 4. Обучение модели и создание артефактов

Команад для пересоздания модели и TF-IDF словарей

```
python src/train_model.py
```

Результат:

- **artifacts/model.pkl** — обученная модель
- **artifacts/tfidf_word.pkl** — TF-IDF слов
- **artifacts/tfidf_char.pkl** — TF-IDF символов

Эти файлы автоматически загружаются на S3/MinIO.

## 5. Генерация сабмита для соревнования

Команда для предсказания на тестовом наборе и создание submission.csv:

```
python src/predict.py
```

## 6. Презентация

Ссылка на презентацию: [https://docs.google.com/presentation/d/16_-i23ugSGf412GE0qiUqZKzQ-qtGbUABUaC1WvkQy0/edit?slide=id.g3b14d45a1b4_0_23#slide=id.g3b14d45a1b4_0_23]


